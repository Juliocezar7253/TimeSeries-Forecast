{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_excel('../Input/DadosCompeticao.xlsx')",
   "id": "1ed062fa9260ee78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### NN com LSTM (bayesian search) -> 3 camadas (WRMSE = 0.08913640587115884)",
   "id": "a1658ad048b886e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecast_window = 12\n",
    "past_window = df.shape[1] - 1"
   ],
   "id": "1b205e2e84250bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def data_preparation(series_scaled, forecast_window, past_window):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series_scaled) - past_window - forecast_window + 1):\n",
    "        X.append(series_scaled[i:i + past_window])\n",
    "        y.append(series_scaled[i + past_window:i + past_window + forecast_window])\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "bd4c9bd9f986f944",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_model(past_window, forecast_window, neurons=100, dropout_rate=0.3, learning_rate=0.001, activation='relu'):\n",
    "    model = Sequential([\n",
    "        LSTM(neurons, activation=activation, return_sequences=True, input_shape=(past_window, 1)),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(neurons, activation=activation, return_sequences=True),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(neurons, activation=activation, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(neurons, activation=activation),\n",
    "        Dense(forecast_window)\n",
    "    ])\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ],
   "id": "b9d05e1d5cd9ef1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def objective(trial, series, forecast_window, past_window, n_splits=3):\n",
    "    ## Set de possibilidades para busca bayesiana\n",
    "    neurons = trial.suggest_categorical(\"neurons\", [50, 100, 150, 300])\n",
    "    dropout_rate = trial.suggest_categorical(\"dropout_rate\", [0.1, 0.2, 0.3, 0.5])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [0.01, 0.001, 0.0005])\n",
    "    activation = trial.suggest_categorical(\"activation\", ['relu', 'tanh', 'sigmoid', 'softmax'])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    series_scaled = scaler.fit_transform(series.reshape(-1, 1))\n",
    "\n",
    "    X, y = data_preparation(series_scaled, forecast_window, past_window)\n",
    "    X = X.reshape((X.shape[0], past_window, 1))\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits) ## -> seguir com split\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = build_model(past_window, forecast_window, neurons, dropout_rate, learning_rate, activation)\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(y_pred.shape)\n",
    "        y_val_rescaled = scaler.inverse_transform(y_val.reshape(-1, 1)).reshape(y_val.shape)\n",
    "\n",
    "        rmse = np.mean([\n",
    "            root_mean_squared_error(y_val_rescaled[:, i], y_pred_rescaled[:, i])\n",
    "            for i in range(forecast_window)\n",
    "        ])\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_scores) ## Função objetivo para minimizar RMSE"
   ],
   "id": "1a155ec2c348109e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def NN_bayesian_search(forecast_window, past_window, n_trials=5):\n",
    "    best_params = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n parâmetros para: {col}\")\n",
    "        series = df[col].values\n",
    "\n",
    "        study = optuna.create_study(direction=\"minimize\") ## min objective s.a set_params\n",
    "        study.optimize(lambda trial: objective(trial, series, forecast_window, past_window), n_trials=n_trials)\n",
    "\n",
    "        best_params[col] = study.best_params\n",
    "\n",
    "    return best_params"
   ],
   "id": "b75c9c4360469f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "params = NN_bayesian_search(forecast_window=forecast_window, past_window=past_window) # muito custoso (out of GPU)",
   "id": "50e4578729b88e51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def NN(best_params, forecast_window, past_window):\n",
    "    scores = {}\n",
    "    forecasts = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        print(f\"\\n ==== Treinando {col} ====\")\n",
    "\n",
    "        series = df[col].values.reshape(-1, 1)\n",
    "        scaler = MinMaxScaler()\n",
    "        series_scaled = scaler.fit_transform(series)\n",
    "\n",
    "        X, y = data_preparation(series_scaled, forecast_window, past_window)\n",
    "        X = X.reshape((X.shape[0], past_window, 1))\n",
    "\n",
    "        params = best_params[col]\n",
    "        model = build_model(\n",
    "            past_window=past_window,\n",
    "            forecast_window=forecast_window,\n",
    "            neurons=params['neurons'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            activation=params['activation']\n",
    "        )\n",
    "\n",
    "        model.fit(X, y, epochs=100, batch_size=32, verbose=0) # Preservar params de fit\n",
    "\n",
    "        # Previsão\n",
    "        last_input = series_scaled[-past_window:].reshape((1, past_window, 1))\n",
    "        forecast = model.predict(last_input)\n",
    "        forecast_rescaled = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()\n",
    "\n",
    "        forecasts[col] = forecast_rescaled\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(y_pred.shape)\n",
    "        y_rescaled = scaler.inverse_transform(y.reshape(-1, 1)).reshape(y.shape)\n",
    "        rmse = np.mean([\n",
    "            root_mean_squared_error(y_rescaled[:, i], y_pred_rescaled[:, i])\n",
    "            for i in range(forecast_window)\n",
    "        ])\n",
    "        scores[col] = rmse\n",
    "\n",
    "    return forecasts, scores"
   ],
   "id": "74c2e863f7e887ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "forecast_set, score_set = NN(best_params=params, forecast_window=forecast_window, past_window=past_window)",
   "id": "c7c4ff3963c34574",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecast = pd.DataFrame(forecast_set)\n",
    "df_scores = pd.DataFrame.from_dict(score_set, orient='index', columns=['RMSE'])"
   ],
   "id": "ea562eaf5874fbce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "forecast.to_excel('../Output/v2_1/previsoes_lstm.xlsx', index=False)\n",
    "df_scores.to_excel('../Output/v2_1/scores_lstm.xlsx')"
   ],
   "id": "f59efca5a17acc13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wrmse = lambda rmse: (rmse[:11] * (1 / 11)).sum()",
   "id": "c873c040a189e109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'WRMSE = {wrmse(df_scores[\"RMSE\"])}')",
   "id": "3b2bb5de4d4fab39",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
